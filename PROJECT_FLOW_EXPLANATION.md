# ğŸ“‹ Project Flow aur Code Explanation (à¤¹à¤¿à¤‚à¤¦à¥€/English)

## ğŸ¯ Project Overview
Yeh ek **Product Data Extraction System** hai jo product pages se structured data extract karta hai using AI.

---

## ğŸ“ Files aur Unka Kaam

### 1. **app.py** - Flask Web Server (Main Entry Point)
**Kaam:**
- Flask web server start karta hai
- User ko web interface provide karta hai
- API endpoints expose karta hai

**Key Functions:**
- `@app.route('/')` - Homepage render karta hai
- `@app.route('/api/extract', methods=['POST'])` - Product URL se data extract karta hai
- `@app.route('/api/fields', methods=['GET'])` - Available fields list return karta hai

**Flow:**
```
User â†’ Web Form â†’ /api/extract â†’ pipeline.run() â†’ Response JSON
```

---

### 2. **pipeline.py** - Main Processing Logic (à¤¸à¤¬à¤¸à¥‡ Important)
**Kaam:**
- Complete extraction pipeline ko handle karta hai
- Screenshot capture â†’ Text extraction â†’ AI model call â†’ JSON parsing

**Key Functions:**

#### `run(url, fields=None)`
Main function jo complete flow ko handle karta hai:

**Step-by-Step Flow:**
1. **Screenshot Capture:**
   ```python
   img_path = capture_fullpage(url, out_path="tmp_page.png")
   ```
   - Playwright use karke full page screenshot leta hai

2. **Text Extraction (2 methods):**
   - **DOM Extraction (First Try):**
     ```python
     extracted_text = fetch_dom_text(url)  # BeautifulSoup
     # OR
     extracted_text = fetch_dom_with_playwright(url)  # JS-rendered content
     ```
   - **OCR Fallback:**
     ```python
     easyocr_text = ocr_easyocr(img_path)
     tesseract_text = ocr_pytesseract(img_path)
     # Combine both results
     ```

3. **AI Model Call:**
   ```python
   prompt = generate_prompt_template(fields)  # Dynamic prompt banata hai
   out = call_hf_inference(prompt)  # Model ko call karta hai
   model_txt = extract_json_from_response(out)
   ```

4. **JSON Parsing:**
   - Model response se JSON extract karta hai
   - Field validation aur type conversion karta hai
   - Fallback values use karta hai (regex-extracted)

#### `generate_prompt_template(fields)`
- Requested fields ke liye dynamic prompt banata hai
- Predefined fields (rating, price, etc.) aur custom fields dono support karta hai
- Detailed extraction rules add karta hai

**Predefined Fields:**
- `rating` - Product rating (0.0 to 5.0)
- `ratings_count` - Total ratings count
- `reviews_count` - Total reviews count
- `review` - Customer review text
- `price` - Current price
- `product_name` - Product title
- `discount` - Discount percentage
- `availability` - Stock status
- `mrp` - Maximum Retail Price

---

### 3. **capture.py** - Screenshot Capture
**Kaam:**
- Playwright use karke web pages ka screenshot leta hai
- Anti-bot detection techniques use karta hai

**Key Functions:**

#### `capture_fullpage(url, out_path)`
- Main function jo screenshot capture karta hai
- Site-specific handling (Amazon, Flipkart, Myntra, etc.)
- Anti-bot detection bypass techniques:
  - User agent spoofing
  - Webdriver property removal
  - Realistic browser context
  - Extra headers

#### `_capture_myntra(url, out_path)`
- Myntra ke liye special handling (strong bot detection)
- Multiple strategies try karta hai:
  1. Mobile user agent
  2. Chromium stealth mode
  3. Non-headless browser
  4. Firefox browser
  5. Alternative Chromium settings

---

### 4. **ocr.py** - Text Extraction from Images
**Kaam:**
- Screenshot images se text extract karta hai
- 2 OCR engines use karta hai: EasyOCR aur pytesseract

**Key Functions:**

#### `ocr_easyocr(image_path)`
- EasyOCR use karta hai (better for mixed fonts)
- Line-by-line structure preserve karta hai
- Bounding boxes se text ordering maintain karta hai

#### `ocr_pytesseract(image_path)`
- Tesseract OCR use karta hai
- Simpler but faster
- Line structure preserve karta hai

**Why Both?**
- EasyOCR: Better accuracy, mixed fonts handle karta hai
- Tesseract: Faster, simpler text
- Combine karke maximum text extraction

---

### 5. **scrape_dom.py** - DOM Text Extraction
**Kaam:**
- HTML DOM se directly text extract karta hai
- JavaScript-rendered content handle karta hai

**Key Functions:**

#### `fetch_dom_text(url)`
- BeautifulSoup use karke simple HTML parse karta hai
- Fast but JavaScript content miss ho sakta hai

#### `fetch_dom_with_playwright(url)`
- Playwright use karke JS-rendered content handle karta hai
- Networkidle wait karta hai (dynamic content load hone ke liye)

#### `extract_rating_from_dom(url)`
- DOM attributes se rating directly extract karta hai
- Flipkart/Amazon ke liye specific selectors use karta hai

---

### 6. **call_model_hf.py** - AI Model Integration
**Kaam:**
- HuggingFace Inference API aur Mistral API ko call karta hai
- Model se structured data extract karta hai

**Key Functions:**

#### `call_hf_inference(prompt, use_mistral_api=False)`
- HuggingFace API call karta hai
- Retry logic with exponential backoff
- Token authentication handle karta hai

#### `call_mistral_api(prompt)`
- Mistral API directly call karta hai
- Rate limit handling
- Timeout handling for large prompts

#### `extract_json_from_response(resp, is_mistral=False)`
- API response se generated text extract karta hai
- Different response formats handle karta hai

**Model Used:**
- Default: `mistralai/Mistral-7B-Instruct-v0.2`
- Mistral API: `mistral-medium` (or `mistral-small`)

---

### 7. **config.py** - Configuration Management
**Kaam:**
- API tokens ko automatically load karta hai
- Environment variables setup karta hai

**Key Functions:**

#### `load_token_from_file()`
- `token.md` ya `.env` file se token read karta hai
- Multiple formats support karta hai:
  - PowerShell: `$env:HF_TOKEN = "token"`
  - Standard: `HF_TOKEN=token`
  - Mistral: `MISTRAL_API_KEY=token`

#### `setup_environment()`
- Environment variables set karta hai
- Token format detect karta hai (HF vs Mistral)

---

### 8. **templates/index.html** - Web UI
**Kaam:**
- User-friendly web interface provide karta hai
- Form for URL input aur field selection

**Features:**
- Predefined fields checkbox selection
- Custom fields input
- Real-time loading indicator
- Formatted results display

---

## ğŸ”„ Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER REQUEST                          â”‚
â”‚  (Web Form ya CLI se URL + Fields)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   app.py (Flask)                         â”‚
â”‚  - /api/extract endpoint receive karta hai               â”‚
â”‚  - setup_environment() call karta hai                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              pipeline.py â†’ run(url, fields)              â”‚
â”‚                                                          â”‚
â”‚  Step 1: Screenshot Capture                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ capture_fullpage(url)                â”‚              â”‚
â”‚  â”‚ â†’ capture.py â†’ Playwright            â”‚              â”‚
â”‚  â”‚ â†’ tmp_page.png save hota hai          â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚                                    â”‚
â”‚                     â–¼                                    â”‚
â”‚  Step 2: Text Extraction (2 methods try)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Method 1: DOM Extraction             â”‚              â”‚
â”‚  â”‚ â†’ scrape_dom.py                      â”‚              â”‚
â”‚  â”‚   - fetch_dom_text() (BeautifulSoup) â”‚              â”‚
â”‚  â”‚   - fetch_dom_with_playwright()      â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Method 2: OCR (Fallback)             â”‚              â”‚
â”‚  â”‚ â†’ ocr.py                              â”‚              â”‚
â”‚  â”‚   - ocr_easyocr()                    â”‚              â”‚
â”‚  â”‚   - ocr_pytesseract()                â”‚              â”‚
â”‚  â”‚   - Combine both results             â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚                                    â”‚
â”‚                     â–¼                                    â”‚
â”‚  Step 3: Prompt Generation                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ generate_prompt_template(fields)      â”‚              â”‚
â”‚  â”‚ - Field definitions add karta hai     â”‚              â”‚
â”‚  â”‚ - Extraction rules add karta hai      â”‚              â”‚
â”‚  â”‚ - Custom fields handle karta hai       â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚                                    â”‚
â”‚                     â–¼                                    â”‚
â”‚  Step 4: AI Model Call                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ call_hf_inference(prompt)             â”‚              â”‚
â”‚  â”‚ â†’ call_model_hf.py                    â”‚              â”‚
â”‚  â”‚   - HuggingFace API ya Mistral API    â”‚              â”‚
â”‚  â”‚   - Token authentication              â”‚              â”‚
â”‚  â”‚   - Retry logic                       â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚                                    â”‚
â”‚                     â–¼                                    â”‚
â”‚  Step 5: JSON Parsing                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ - Extract JSON from model response    â”‚              â”‚
â”‚  â”‚ - Validate field types                â”‚              â”‚
â”‚  â”‚ - Apply fallback values (regex)       â”‚              â”‚
â”‚  â”‚ - Filter to requested fields only     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                     â”‚                                    â”‚
â”‚                     â–¼                                    â”‚
â”‚              RETURN JSON RESULT                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              app.py â†’ JSON Response                     â”‚
â”‚              â†’ Web UI ya CLI output                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Features

### 1. **Dual Extraction Strategy**
- **DOM First:** Fast, accurate, structured data
- **OCR Fallback:** Works for any site, visual content handle karta hai

### 2. **Field Flexibility**
- **Predefined Fields:** rating, price, mrp, etc. (with detailed rules)
- **Custom Fields:** Any field name (e.g., "Operating System", "SELECT SIZE")

### 3. **AI-Powered Extraction**
- Mistral 7B Instruct model use karta hai
- Line-by-line reading instructions
- OCR errors handle karta hai
- Structured JSON output

### 4. **Error Handling**
- Multiple fallback strategies
- Retry logic with exponential backoff
- Graceful degradation

### 5. **Site-Specific Handling**
- Amazon: Longer timeouts
- Flipkart: Networkidle wait
- Myntra: Multiple anti-bot strategies
- Generic: Default strategy

---

## ğŸ“ Usage Examples

### CLI Usage:
```bash
# Basic usage
python pipeline.py "https://www.flipkart.com/product-url"

# With specific fields
python pipeline.py "https://..." rating price mrp

# PowerShell script
.\run_pipeline.ps1 -Url "https://..." -Fields rating,price
```

### Web UI:
```bash
python app.py
# Open http://localhost:5000
```

### API Usage:
```bash
curl -X POST http://localhost:5000/api/extract \
  -H "Content-Type: application/json" \
  -d '{"url": "https://...", "fields": ["rating", "price"]}'
```

---

## ğŸ› ï¸ Dependencies

**Main Libraries:**
- `playwright` - Browser automation
- `flask` - Web server
- `easyocr` / `pytesseract` - OCR
- `beautifulsoup4` - HTML parsing
- `requests` - API calls

**Model APIs:**
- HuggingFace Inference API
- Mistral API

---

## âš™ï¸ Configuration

**Token Setup:**
1. `token.md` file me:
   ```
   $env:HF_TOKEN = "hf_..."
   ```
   ya
   ```
   $env:MISTRAL_API_KEY = "your_key"
   ```

2. Ya `.env` file me:
   ```
   HF_TOKEN=hf_...
   ```

**Environment Variables:**
- `HF_TOKEN` - HuggingFace token
- `MISTRAL_API_KEY` - Mistral API key
- `PORT` - Flask server port (default: 5000)

---

## ğŸ¯ Summary

**Yeh system:**
1. Product URL le ke screenshot capture karta hai
2. Text extract karta hai (DOM ya OCR se)
3. AI model ko prompt bhejta hai with extraction rules
4. Structured JSON me data return karta hai

**Key Advantage:**
- Works with any e-commerce site
- Custom fields support
- Visual content (screenshots) se bhi extract karta hai
- AI-powered, accurate extraction

---

## ğŸ“Š File Dependencies

```
app.py
  â”œâ”€â”€ pipeline.py (run function)
  â”‚     â”œâ”€â”€ capture.py (screenshot)
  â”‚     â”œâ”€â”€ ocr.py (text from image)
  â”‚     â”œâ”€â”€ scrape_dom.py (text from HTML)
  â”‚     â””â”€â”€ call_model_hf.py (AI model)
  â””â”€â”€ config.py (token loading)
```

---

**End of Explanation** ğŸ‰

